#!/usr/bin/env python3
"""
æ‰‹åŠ¨æ•°æ®å¯¼å…¥è„šæœ¬
å½“æ— æ³•è‡ªåŠ¨è¿æ¥Prestoæ—¶ï¼Œå¯ä»¥æ‰‹åŠ¨æ‰§è¡ŒSQLå¹¶å¯¼å…¥ç»“æœ
"""
import sqlite3
import pandas as pd
import json
from datetime import datetime
import os

class ManualDataImporter:
    def __init__(self, local_db_path: str = "./data.db"):
        self.local_db_path = local_db_path
    
    def import_from_csv(self, csv_file_path: str, table_name: str = "cpz_qs_newuser_channel_i_d") -> bool:
        """ä»CSVæ–‡ä»¶å¯¼å…¥æ•°æ®"""
        if not os.path.exists(csv_file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
            return False
        
        try:
            # è¯»å–CSVæ–‡ä»¶
            print(f"ğŸ“– è¯»å–CSVæ–‡ä»¶: {csv_file_path}")
            df = pd.read_csv(csv_file_path)
            print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡è®°å½•")
            
            # æ˜¾ç¤ºæ•°æ®ç»“æ„
            print(f"ğŸ“Š æ•°æ®ç»“æ„:")
            print(f"  - åˆ—æ•°: {len(df.columns)}")
            print(f"  - åˆ—å: {list(df.columns)}")
            
            # å¯¼å…¥åˆ°SQLite
            return self._import_dataframe(df, table_name)
            
        except Exception as e:
            print(f"âŒ CSVå¯¼å…¥å¤±è´¥: {e}")
            return False
    
    def import_from_json(self, json_file_path: str, table_name: str = "cpz_qs_newuser_channel_i_d") -> bool:
        """ä»JSONæ–‡ä»¶å¯¼å…¥æ•°æ®"""
        if not os.path.exists(json_file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
            return False
        
        try:
            # è¯»å–JSONæ–‡ä»¶
            print(f"ğŸ“– è¯»å–JSONæ–‡ä»¶: {json_file_path}")
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data)
            print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡è®°å½•")
            
            # å¯¼å…¥åˆ°SQLite
            return self._import_dataframe(df, table_name)
            
        except Exception as e:
            print(f"âŒ JSONå¯¼å…¥å¤±è´¥: {e}")
            return False
    
    def _import_dataframe(self, df: pd.DataFrame, table_name: str) -> bool:
        """å°†DataFrameå¯¼å…¥åˆ°SQLite"""
        try:
            conn = sqlite3.connect(self.local_db_path)
            
            # æ£€æŸ¥æ•°æ®æ—¥æœŸèŒƒå›´
            if 'dt' in df.columns:
                dates = df['dt'].unique()
                print(f"ğŸ“… æ•°æ®æ—¥æœŸèŒƒå›´: {min(dates)} åˆ° {max(dates)}")
                
                # æ¸…ç†ç›¸åŒæ—¥æœŸçš„ç°æœ‰æ•°æ®
                cursor = conn.cursor()
                for date in dates:
                    cursor.execute(f"DELETE FROM {table_name} WHERE dt = ?", [date])
                    print(f"ğŸ—‘ï¸ æ¸…ç† {date} çš„æ—§æ•°æ®")
                conn.commit()
            
            # å¯¼å…¥æ–°æ•°æ®
            df.to_sql(table_name, conn, if_exists='append', index=False)
            
            conn.close()
            print(f"âœ… æˆåŠŸå¯¼å…¥ {len(df)} æ¡è®°å½•åˆ° {table_name}")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“å¯¼å…¥å¤±è´¥: {e}")
            return False
    
    def create_sample_instructions(self):
        """åˆ›å»ºæ‰‹åŠ¨æ“ä½œè¯´æ˜"""
        instructions = """
# æ‰‹åŠ¨æ•°æ®å¯¼å…¥è¯´æ˜

## æ–¹æ³•1: é€šè¿‡DataGripå¯¼å‡ºCSV

1. åœ¨DataGripä¸­æ‰“å¼€SQLæ§åˆ¶å°
2. æ‰§è¡Œ cpz_qs_newuser_channel_i_d.sql è„šæœ¬
3. å³é”®æŸ¥è¯¢ç»“æœ -> Export Data -> CSV
4. ä¿å­˜ä¸º data_export.csv
5. è¿è¡Œ: python3 manual_data_import.py --csv data_export.csv

## æ–¹æ³•2: æ‰‹åŠ¨é…ç½®Prestoè¿æ¥

1. ç¼–è¾‘ presto_config.py
2. å¡«å…¥æ­£ç¡®çš„è¿æ¥å‚æ•°:
   - host: PrestoæœåŠ¡å™¨åœ°å€
   - port: ç«¯å£ï¼ˆé€šå¸¸8080ï¼‰
   - catalog: æ•°æ®ç›®å½•
   - schema: æ•°æ®åº“schemaï¼ˆdaï¼‰
   - user: ç”¨æˆ·å

## æ–¹æ³•3: ä½¿ç”¨ç°æœ‰æ¨¡æ‹Ÿæ•°æ®

å¦‚æœçº¿ä¸Šæ•°æ®æš‚æ—¶æ— æ³•è®¿é—®ï¼Œå¯ä»¥ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç»§ç»­å¼€å‘:
1. è¿è¡Œ: python3 src/data_updater.py
2. ç”Ÿæˆæ›´å¤šæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•

## ç¤ºä¾‹å‘½ä»¤

```bash
# å¯¼å…¥CSVæ–‡ä»¶
python3 manual_data_import.py --csv /path/to/export.csv

# å¯¼å…¥JSONæ–‡ä»¶  
python3 manual_data_import.py --json /path/to/export.json

# ç”Ÿæˆæ›´å¤šæ¨¡æ‹Ÿæ•°æ®
python3 src/data_updater.py
```
"""
        
        with open("data_import_instructions.md", "w") as f:
            f.write(instructions)
        
        print("ğŸ“„ æ“ä½œè¯´æ˜å·²åˆ›å»º: data_import_instructions.md")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="æ‰‹åŠ¨æ•°æ®å¯¼å…¥å·¥å…·")
    parser.add_argument("--csv", help="CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--json", help="JSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--table", default="cpz_qs_newuser_channel_i_d", help="ç›®æ ‡è¡¨å")
    parser.add_argument("--instructions", action="store_true", help="ç”Ÿæˆæ“ä½œè¯´æ˜")
    
    args = parser.parse_args()
    
    importer = ManualDataImporter()
    
    if args.instructions:
        importer.create_sample_instructions()
        return
    
    if args.csv:
        success = importer.import_from_csv(args.csv, args.table)
    elif args.json:
        success = importer.import_from_json(args.json, args.table)
    else:
        print("è¯·æŒ‡å®šè¦å¯¼å…¥çš„æ–‡ä»¶ç±»å‹ (--csv æˆ– --json)")
        print("æˆ–ä½¿ç”¨ --instructions æŸ¥çœ‹è¯¦ç»†è¯´æ˜")
        return
    
    if success:
        print("ğŸ‰ æ•°æ®å¯¼å…¥å®Œæˆï¼")
        print("ç°åœ¨å¯ä»¥è¿è¡Œå·¥ä½œæµåˆ†ææœ€æ–°æ•°æ®:")
        print("  python3 src/workflow.py")
    else:
        print("âŒ æ•°æ®å¯¼å…¥å¤±è´¥")

if __name__ == "__main__":
    main()